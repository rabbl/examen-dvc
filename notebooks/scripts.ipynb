{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T11:45:04.156613Z",
     "start_time": "2025-01-11T11:45:04.149726Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  date  ave_flot_air_flow  ave_flot_level  iron_feed  \\\n",
       "0  2017-04-24 00:00:00         300.263166      383.982443      55.17   \n",
       "1  2017-04-24 01:00:00         299.782402      386.049069      55.17   \n",
       "2  2017-04-24 02:00:00         299.750052      385.250935      55.17   \n",
       "3  2017-04-24 03:00:00         299.997522      389.635519      55.17   \n",
       "4  2017-04-24 04:00:00         300.005220      387.810807      55.17   \n",
       "\n",
       "   starch_flow  amina_flow  ore_pulp_flow  ore_pulp_pH  ore_pulp_density  \\\n",
       "0  1979.589150  599.676489     400.017222     9.774028          1.753206   \n",
       "1  1758.466329  600.043100     400.484528     9.539246          1.754190   \n",
       "2  2379.752428  599.948406     400.325617     9.434227          1.756873   \n",
       "3  2287.130046  599.580383     399.801506     9.725607          1.727125   \n",
       "4  2291.789167  599.871217     399.567333     9.845198          1.633063   \n",
       "\n",
       "   silica_concentrate  \n",
       "0            4.360000  \n",
       "1            3.290000  \n",
       "2            4.900000  \n",
       "3            4.860153  \n",
       "4            4.780898  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ave_flot_air_flow</th>\n",
       "      <th>ave_flot_level</th>\n",
       "      <th>iron_feed</th>\n",
       "      <th>starch_flow</th>\n",
       "      <th>amina_flow</th>\n",
       "      <th>ore_pulp_flow</th>\n",
       "      <th>ore_pulp_pH</th>\n",
       "      <th>ore_pulp_density</th>\n",
       "      <th>silica_concentrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-24 00:00:00</td>\n",
       "      <td>300.263166</td>\n",
       "      <td>383.982443</td>\n",
       "      <td>55.17</td>\n",
       "      <td>1979.589150</td>\n",
       "      <td>599.676489</td>\n",
       "      <td>400.017222</td>\n",
       "      <td>9.774028</td>\n",
       "      <td>1.753206</td>\n",
       "      <td>4.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-24 01:00:00</td>\n",
       "      <td>299.782402</td>\n",
       "      <td>386.049069</td>\n",
       "      <td>55.17</td>\n",
       "      <td>1758.466329</td>\n",
       "      <td>600.043100</td>\n",
       "      <td>400.484528</td>\n",
       "      <td>9.539246</td>\n",
       "      <td>1.754190</td>\n",
       "      <td>3.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-24 02:00:00</td>\n",
       "      <td>299.750052</td>\n",
       "      <td>385.250935</td>\n",
       "      <td>55.17</td>\n",
       "      <td>2379.752428</td>\n",
       "      <td>599.948406</td>\n",
       "      <td>400.325617</td>\n",
       "      <td>9.434227</td>\n",
       "      <td>1.756873</td>\n",
       "      <td>4.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-24 03:00:00</td>\n",
       "      <td>299.997522</td>\n",
       "      <td>389.635519</td>\n",
       "      <td>55.17</td>\n",
       "      <td>2287.130046</td>\n",
       "      <td>599.580383</td>\n",
       "      <td>399.801506</td>\n",
       "      <td>9.725607</td>\n",
       "      <td>1.727125</td>\n",
       "      <td>4.860153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-24 04:00:00</td>\n",
       "      <td>300.005220</td>\n",
       "      <td>387.810807</td>\n",
       "      <td>55.17</td>\n",
       "      <td>2291.789167</td>\n",
       "      <td>599.871217</td>\n",
       "      <td>399.567333</td>\n",
       "      <td>9.845198</td>\n",
       "      <td>1.633063</td>\n",
       "      <td>4.780898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T11:46:01.326147Z",
     "start_time": "2025-01-11T11:46:01.311930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data Splitting:\n",
    "# Split the data into training and testing sets. Our target variable is silica_concentrate, located in the last column of the dataset.\n",
    "# This script will produce 4 datasets (X_test, X_train, y_test, y_train) that you can store in data/processed.\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd(), '../data/raw_data/raw.csv'))\n",
    "\n",
    "X = df.drop(columns=['silica_concentrate'])\n",
    "y = df['silica_concentrate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.to_csv(os.path.join(os.getcwd(), '../data/processed_data/X_train.csv'), index=False)\n",
    "X_test.to_csv(os.path.join(os.getcwd(), '../data/processed_data/X_test.csv'), index=False)\n",
    "\n",
    "y_train.to_csv(os.path.join(os.getcwd(), '../data/processed_data/y_train.csv'), index=False)\n",
    "y_test.to_csv(os.path.join(os.getcwd(), '../data/processed_data/y_test.csv'), index=False)"
   ],
   "id": "3c7ba2bd87788a3f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T11:44:51.329350Z",
     "start_time": "2025-01-11T11:44:51.321682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data Normalization: As you may notice, the data varies widely in scale, so normalization is necessary.\n",
    "# You can use existing functions to construct this script.\n",
    "# As output, this script will create two new datasets (X_train_scaled, X_test_scaled) which you will also save in data/processed.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = pd.read_csv(os.path.join(os.getcwd(), '../data/processed_data/X_train.csv'))\n",
    "X_test = pd.read_csv(os.path.join(os.getcwd(), '../data/processed_data/X_test.csv'))\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "X_train_scaled.to_csv(os.path.join(os.getcwd(), '../data/processed_data/X_train_scaled.csv'), index=False)\n",
    "X_test_scaled.to_csv(os.path.join(os.getcwd(), '../data/processed_data/X_test_scaled.csv'), index=False)\n",
    "\n",
    "print(\"Data normalized successfully.\")"
   ],
   "id": "75a0c5fd2bf81033",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  date  ave_flot_air_flow  ave_flot_level  iron_feed  \\\n",
       "0  2017-04-24 00:00:00         300.263166      383.982443      55.17   \n",
       "1  2017-04-24 01:00:00         299.782402      386.049069      55.17   \n",
       "2  2017-04-24 02:00:00         299.750052      385.250935      55.17   \n",
       "3  2017-04-24 03:00:00         299.997522      389.635519      55.17   \n",
       "4  2017-04-24 04:00:00         300.005220      387.810807      55.17   \n",
       "\n",
       "   starch_flow  amina_flow  ore_pulp_flow  ore_pulp_pH  ore_pulp_density  \\\n",
       "0  1979.589150  599.676489     400.017222     9.774028          1.753206   \n",
       "1  1758.466329  600.043100     400.484528     9.539246          1.754190   \n",
       "2  2379.752428  599.948406     400.325617     9.434227          1.756873   \n",
       "3  2287.130046  599.580383     399.801506     9.725607          1.727125   \n",
       "4  2291.789167  599.871217     399.567333     9.845198          1.633063   \n",
       "\n",
       "   silica_concentrate  \n",
       "0            4.360000  \n",
       "1            3.290000  \n",
       "2            4.900000  \n",
       "3            4.860153  \n",
       "4            4.780898  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ave_flot_air_flow</th>\n",
       "      <th>ave_flot_level</th>\n",
       "      <th>iron_feed</th>\n",
       "      <th>starch_flow</th>\n",
       "      <th>amina_flow</th>\n",
       "      <th>ore_pulp_flow</th>\n",
       "      <th>ore_pulp_pH</th>\n",
       "      <th>ore_pulp_density</th>\n",
       "      <th>silica_concentrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-24 00:00:00</td>\n",
       "      <td>300.263166</td>\n",
       "      <td>383.982443</td>\n",
       "      <td>55.17</td>\n",
       "      <td>1979.589150</td>\n",
       "      <td>599.676489</td>\n",
       "      <td>400.017222</td>\n",
       "      <td>9.774028</td>\n",
       "      <td>1.753206</td>\n",
       "      <td>4.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-24 01:00:00</td>\n",
       "      <td>299.782402</td>\n",
       "      <td>386.049069</td>\n",
       "      <td>55.17</td>\n",
       "      <td>1758.466329</td>\n",
       "      <td>600.043100</td>\n",
       "      <td>400.484528</td>\n",
       "      <td>9.539246</td>\n",
       "      <td>1.754190</td>\n",
       "      <td>3.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-24 02:00:00</td>\n",
       "      <td>299.750052</td>\n",
       "      <td>385.250935</td>\n",
       "      <td>55.17</td>\n",
       "      <td>2379.752428</td>\n",
       "      <td>599.948406</td>\n",
       "      <td>400.325617</td>\n",
       "      <td>9.434227</td>\n",
       "      <td>1.756873</td>\n",
       "      <td>4.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-24 03:00:00</td>\n",
       "      <td>299.997522</td>\n",
       "      <td>389.635519</td>\n",
       "      <td>55.17</td>\n",
       "      <td>2287.130046</td>\n",
       "      <td>599.580383</td>\n",
       "      <td>399.801506</td>\n",
       "      <td>9.725607</td>\n",
       "      <td>1.727125</td>\n",
       "      <td>4.860153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-24 04:00:00</td>\n",
       "      <td>300.005220</td>\n",
       "      <td>387.810807</td>\n",
       "      <td>55.17</td>\n",
       "      <td>2291.789167</td>\n",
       "      <td>599.871217</td>\n",
       "      <td>399.567333</td>\n",
       "      <td>9.845198</td>\n",
       "      <td>1.633063</td>\n",
       "      <td>4.780898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# GridSearch for Best Parameters: Decide on the regression model to implement and the parameters to test.\n",
    "# At the end of this script, we will have the best parameters saved as a .pkl file in the models directory.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train = pd.read_csv(os.path.join(os.getcwd(), '../data/processed_data/X_train_scaled.csv'))\n",
    "y_train = pd.read_csv(os.path.join(os.getcwd(), '../data/processed_data/y_train.csv'))\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(best_params, os.path.join(os.getcwd(), '../models/best_params.pkl'))\n",
    "print(\"Best parameters saved successfully.\")\n"
   ],
   "id": "bffc257ef8ad1745"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Model Training: Using the parameters found through GridSearch, we will train the model and save the trained model in the models directory.\n",
    "\n",
    "X_train = pd.read_csv(os.path.join(os.getcwd(), '../data/processed_data/X_train_scaled.csv'))\n",
    "y_train = pd.read_csv(os.path.join(os.getcwd(), '../data/processed_data/y_train.csv'))\n",
    "\n",
    "best_params = joblib.load(os.path.join(os.getcwd(), '../models/best_params.pkl'))\n",
    "\n",
    "rf = RandomForestRegressor(**best_params)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(rf, os.path.join(os.getcwd(), '../models/trained_model.pkl'))\n",
    "\n",
    "print(\"Model trained and saved successfully.\")"
   ],
   "id": "eafed996b6506e3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Model Evaluation: Finally, using the trained model, we will evaluate its performance and make predictions.\n",
    "# At the end of this script, we will have a new dataset in data containing the predictions,\n",
    "# along with a scores.json file in the metrics directory that will capture evaluation metrics of our model (e.g., MSE, R2).\n",
    "\n",
    "X_test = pd.read_csv(os.path.join(os.getcwd(), '../data/processed_data/X_test_scaled.csv'))\n",
    "y_test = pd.read_csv(os.path.join(os.getcwd(), '../data/processed_data/y_test.csv'))\n",
    "\n",
    "rf = joblib.load(os.path.join(os.getcwd(), '../models/trained_model.pkl'))\n",
    "\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "scores = {\n",
    "    'mse': mse,\n",
    "    'r2': r2\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(os.path.join(os.getcwd(), '../metrics/scores.json'), 'w') as f:\n",
    "    json.dump(scores, f)\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions, columns=['silica_concentrate'])\n",
    "predictions_df.to_csv(os.path.join(os.getcwd(), '../data/predictions/predictions.csv'), index=False)\n",
    "\n",
    "print(\"Model evaluated successfully.\")\n"
   ],
   "id": "bd6c56e4e3879f31"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
